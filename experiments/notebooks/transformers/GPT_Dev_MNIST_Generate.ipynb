{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirhk-dev/MNIST-Lab/blob/main/experiments/notebooks/transformers/GPT_Dev_MNIST_Generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWY-yZBbZftS"
      },
      "source": [
        "#This notebook is relevant to the prior notebook in [text generation](https://github.com/Amirhk-dev/MNIST-Lab/blob/main/experiments/notebooks/transformers/GPT_Dev_Text_Generate.ipynb).\n",
        "\n",
        "Here, the focus is on [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) (containing handwritten digits). \n",
        "\n",
        "The simple version of the transformer is trained on first 9K images of this dataset.\n",
        "\n",
        "The model must be trained on GPU because otherwise it will take ages to train. At inference time, using CPU will be sufficient.\n",
        "\n",
        "Goal: the goal is to make a pre-trained transformer to generate similar images to MNIST images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lSilzk55R9Ub"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTadvVbQ6Y1g",
        "outputId": "8f8cc1c5-04e4-4834-c3bb-80b22aad7e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? False\n"
          ]
        }
      ],
      "source": [
        "gpu_availability = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_availability}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJoNzKuJ6ctT",
        "outputId": "8646f4a8-acf9-4787-ac57-c8c4ab4db710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The using device is: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if gpu_availability else torch.device(\"cpu\")\n",
        "print(f\"The using device is: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o4f4Nbab6ogK"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.MNIST('datasets/MNIST',\n",
        "                               transform = transform,\n",
        "                               download = True,\n",
        "                               train = True)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(train_dataset,\n",
        "                                                   [50000, 10000])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation of 10 images on the trainset of MNIST dataset"
      ],
      "metadata": {
        "id": "4Rvg4V5TLs7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(28, 28))\n",
        "for i in range(1, 11):\n",
        "    img = train_set[i][0][0]\n",
        "    fig.add_subplot(1, 10, i)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "8SeTyzB9Mc7q",
        "outputId": "8fa1a088-2c22-435b-9c7c-53d37e08479f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering pixel values in an image as being characters on a text!\n",
        "\n",
        "The end of an image is shown by an integer 1000."
      ],
      "metadata": {
        "id": "mS3_9cEmxzX7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jf5stiRx6oVR"
      },
      "outputs": [],
      "source": [
        "train_data = []\n",
        "counter = 0\n",
        "for idx in range(len(train_set)):\n",
        "  img = train_set[idx][0][0]\n",
        "  a = img.reshape(-1)\n",
        "  train_data.extend(a)\n",
        "  train_data.extend([1000])\n",
        "  \n",
        "  if counter > 10000:\n",
        "    break\n",
        "  \n",
        "  counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xv7F4VpE2LjW"
      },
      "outputs": [],
      "source": [
        "max_iters = 7000\n",
        "learning_rate = 3e-4\n",
        "dropout = 0.2\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 256 # what is the maximum context length for predictions?\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "\n",
        "CHECKPOINT_PATH = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4idC9CtZaWk",
        "outputId": "4fd16528-0994-43ce-92ea-484b3be66948"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f11284ddab0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "torch.manual_seed(42) # 42 = 101010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fpNaO7TLS9of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c210f3c-9fc9-41ac-b9db-a87064af73a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of different characters:  257\n"
          ]
        }
      ],
      "source": [
        "# here are all the unique pixel values that occur in the images\n",
        "chars = np.unique(train_data)\n",
        "vocab_size = len(chars)\n",
        "print(\"number of different characters: \", vocab_size)\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[float(c)] for c in s] \n",
        "decode = lambda l: [itos[i] for i in l]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDWQ4Gi3I7yw",
        "outputId": "856eb0fa-050d-472f-aed1-81097f74418d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0.0: 0, 0.003921568859368563: 1, 0.007843137718737125: 2, 0.0117647061124444: 3, 0.01568627543747425: 4, 0.019607843831181526: 5, 0.0235294122248888: 6, 0.027450980618596077: 7, 0.0313725508749485: 8, 0.03529411926865578: 9, 0.03921568766236305: 10, 0.04313725605607033: 11, 0.0470588244497776: 12, 0.05098039284348488: 13, 0.054901961237192154: 14, 0.05882352963089943: 15, 0.062745101749897: 16, 0.06666667014360428: 17, 0.07058823853731155: 18, 0.07450980693101883: 19, 0.0784313753247261: 20, 0.08235294371843338: 21, 0.08627451211214066: 22, 0.09019608050584793: 23, 0.0941176488995552: 24, 0.09803921729326248: 25, 0.10196078568696976: 26, 0.10588235408067703: 27, 0.10980392247438431: 28, 0.11372549086809158: 29, 0.11764705926179886: 30, 0.12156862765550613: 31, 0.125490203499794: 32, 0.12941177189350128: 33, 0.13333334028720856: 34, 0.13725490868091583: 35, 0.1411764770746231: 36, 0.14509804546833038: 37, 0.14901961386203766: 38, 0.15294118225574493: 39, 0.1568627506494522: 40, 0.16078431904315948: 41, 0.16470588743686676: 42, 0.16862745583057404: 43, 0.1725490242242813: 44, 0.1764705926179886: 45, 0.18039216101169586: 46, 0.18431372940540314: 47, 0.1882352977991104: 48, 0.1921568661928177: 49, 0.19607843458652496: 50, 0.20000000298023224: 51, 0.20392157137393951: 52, 0.2078431397676468: 53, 0.21176470816135406: 54, 0.21568627655506134: 55, 0.21960784494876862: 56, 0.2235294133424759: 57, 0.22745098173618317: 58, 0.23137255012989044: 59, 0.23529411852359772: 60, 0.239215686917305: 61, 0.24313725531101227: 62, 0.24705882370471954: 63, 0.250980406999588: 64, 0.2549019753932953: 65, 0.25882354378700256: 66, 0.26274511218070984: 67, 0.2666666805744171: 68, 0.2705882489681244: 69, 0.27450981736183167: 70, 0.27843138575553894: 71, 0.2823529541492462: 72, 0.2862745225429535: 73, 0.29019609093666077: 74, 0.29411765933036804: 75, 0.2980392277240753: 76, 0.3019607961177826: 77, 0.30588236451148987: 78, 0.30980393290519714: 79, 0.3137255012989044: 80, 0.3176470696926117: 81, 0.32156863808631897: 82, 0.32549020648002625: 83, 0.3294117748737335: 84, 0.3333333432674408: 85, 0.33725491166114807: 86, 0.34117648005485535: 87, 0.3450980484485626: 88, 0.3490196168422699: 89, 0.3529411852359772: 90, 0.35686275362968445: 91, 0.3607843220233917: 92, 0.364705890417099: 93, 0.3686274588108063: 94, 0.37254902720451355: 95, 0.3764705955982208: 96, 0.3803921639919281: 97, 0.3843137323856354: 98, 0.38823530077934265: 99, 0.3921568691730499: 100, 0.3960784375667572: 101, 0.4000000059604645: 102, 0.40392157435417175: 103, 0.40784314274787903: 104, 0.4117647111415863: 105, 0.4156862795352936: 106, 0.41960784792900085: 107, 0.42352941632270813: 108, 0.4274509847164154: 109, 0.4313725531101227: 110, 0.43529412150382996: 111, 0.43921568989753723: 112, 0.4431372582912445: 113, 0.4470588266849518: 114, 0.45098039507865906: 115, 0.45490196347236633: 116, 0.4588235318660736: 117, 0.4627451002597809: 118, 0.46666666865348816: 119, 0.47058823704719543: 120, 0.4745098054409027: 121, 0.47843137383461: 122, 0.48235294222831726: 123, 0.48627451062202454: 124, 0.4901960790157318: 125, 0.4941176474094391: 126, 0.49803921580314636: 127, 0.501960813999176: 128, 0.5058823823928833: 129, 0.5098039507865906: 130, 0.5137255191802979: 131, 0.5176470875740051: 132, 0.5215686559677124: 133, 0.5254902243614197: 134, 0.529411792755127: 135, 0.5333333611488342: 136, 0.5372549295425415: 137, 0.5411764979362488: 138, 0.545098066329956: 139, 0.5490196347236633: 140, 0.5529412031173706: 141, 0.5568627715110779: 142, 0.5607843399047852: 143, 0.5647059082984924: 144, 0.5686274766921997: 145, 0.572549045085907: 146, 0.5764706134796143: 147, 0.5803921818733215: 148, 0.5843137502670288: 149, 0.5882353186607361: 150, 0.5921568870544434: 151, 0.5960784554481506: 152, 0.6000000238418579: 153, 0.6039215922355652: 154, 0.6078431606292725: 155, 0.6117647290229797: 156, 0.615686297416687: 157, 0.6196078658103943: 158, 0.6235294342041016: 159, 0.6274510025978088: 160, 0.6313725709915161: 161, 0.6352941393852234: 162, 0.6392157077789307: 163, 0.6431372761726379: 164, 0.6470588445663452: 165, 0.6509804129600525: 166, 0.6549019813537598: 167, 0.658823549747467: 168, 0.6627451181411743: 169, 0.6666666865348816: 170, 0.6705882549285889: 171, 0.6745098233222961: 172, 0.6784313917160034: 173, 0.6823529601097107: 174, 0.686274528503418: 175, 0.6901960968971252: 176, 0.6941176652908325: 177, 0.6980392336845398: 178, 0.7019608020782471: 179, 0.7058823704719543: 180, 0.7098039388656616: 181, 0.7137255072593689: 182, 0.7176470756530762: 183, 0.7215686440467834: 184, 0.7254902124404907: 185, 0.729411780834198: 186, 0.7333333492279053: 187, 0.7372549176216125: 188, 0.7411764860153198: 189, 0.7450980544090271: 190, 0.7490196228027344: 191, 0.7529411911964417: 192, 0.7568627595901489: 193, 0.7607843279838562: 194, 0.7647058963775635: 195, 0.7686274647712708: 196, 0.772549033164978: 197, 0.7764706015586853: 198, 0.7803921699523926: 199, 0.7843137383460999: 200, 0.7882353067398071: 201, 0.7921568751335144: 202, 0.7960784435272217: 203, 0.800000011920929: 204, 0.8039215803146362: 205, 0.8078431487083435: 206, 0.8117647171020508: 207, 0.8156862854957581: 208, 0.8196078538894653: 209, 0.8235294222831726: 210, 0.8274509906768799: 211, 0.8313725590705872: 212, 0.8352941274642944: 213, 0.8392156958580017: 214, 0.843137264251709: 215, 0.8470588326454163: 216, 0.8509804010391235: 217, 0.8549019694328308: 218, 0.8588235378265381: 219, 0.8627451062202454: 220, 0.8666666746139526: 221, 0.8705882430076599: 222, 0.8745098114013672: 223, 0.8784313797950745: 224, 0.8823529481887817: 225, 0.886274516582489: 226, 0.8901960849761963: 227, 0.8941176533699036: 228, 0.8980392217636108: 229, 0.9019607901573181: 230, 0.9058823585510254: 231, 0.9098039269447327: 232, 0.9137254953384399: 233, 0.9176470637321472: 234, 0.9215686321258545: 235, 0.9254902005195618: 236, 0.929411768913269: 237, 0.9333333373069763: 238, 0.9372549057006836: 239, 0.9411764740943909: 240, 0.9450980424880981: 241, 0.9490196108818054: 242, 0.9529411792755127: 243, 0.95686274766922: 244, 0.9607843160629272: 245, 0.9647058844566345: 246, 0.9686274528503418: 247, 0.9725490212440491: 248, 0.9764705896377563: 249, 0.9803921580314636: 250, 0.9843137264251709: 251, 0.9882352948188782: 252, 0.9921568632125854: 253, 0.9960784316062927: 254, 1.0: 255, 1000.0: 256}\n"
          ]
        }
      ],
      "source": [
        "print(stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5SxIqU8LN2F",
        "outputId": "e9faeb8f-27a2-4109-cf89-0ec29210c343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.0, 1: 0.003921568859368563, 2: 0.007843137718737125, 3: 0.0117647061124444, 4: 0.01568627543747425, 5: 0.019607843831181526, 6: 0.0235294122248888, 7: 0.027450980618596077, 8: 0.0313725508749485, 9: 0.03529411926865578, 10: 0.03921568766236305, 11: 0.04313725605607033, 12: 0.0470588244497776, 13: 0.05098039284348488, 14: 0.054901961237192154, 15: 0.05882352963089943, 16: 0.062745101749897, 17: 0.06666667014360428, 18: 0.07058823853731155, 19: 0.07450980693101883, 20: 0.0784313753247261, 21: 0.08235294371843338, 22: 0.08627451211214066, 23: 0.09019608050584793, 24: 0.0941176488995552, 25: 0.09803921729326248, 26: 0.10196078568696976, 27: 0.10588235408067703, 28: 0.10980392247438431, 29: 0.11372549086809158, 30: 0.11764705926179886, 31: 0.12156862765550613, 32: 0.125490203499794, 33: 0.12941177189350128, 34: 0.13333334028720856, 35: 0.13725490868091583, 36: 0.1411764770746231, 37: 0.14509804546833038, 38: 0.14901961386203766, 39: 0.15294118225574493, 40: 0.1568627506494522, 41: 0.16078431904315948, 42: 0.16470588743686676, 43: 0.16862745583057404, 44: 0.1725490242242813, 45: 0.1764705926179886, 46: 0.18039216101169586, 47: 0.18431372940540314, 48: 0.1882352977991104, 49: 0.1921568661928177, 50: 0.19607843458652496, 51: 0.20000000298023224, 52: 0.20392157137393951, 53: 0.2078431397676468, 54: 0.21176470816135406, 55: 0.21568627655506134, 56: 0.21960784494876862, 57: 0.2235294133424759, 58: 0.22745098173618317, 59: 0.23137255012989044, 60: 0.23529411852359772, 61: 0.239215686917305, 62: 0.24313725531101227, 63: 0.24705882370471954, 64: 0.250980406999588, 65: 0.2549019753932953, 66: 0.25882354378700256, 67: 0.26274511218070984, 68: 0.2666666805744171, 69: 0.2705882489681244, 70: 0.27450981736183167, 71: 0.27843138575553894, 72: 0.2823529541492462, 73: 0.2862745225429535, 74: 0.29019609093666077, 75: 0.29411765933036804, 76: 0.2980392277240753, 77: 0.3019607961177826, 78: 0.30588236451148987, 79: 0.30980393290519714, 80: 0.3137255012989044, 81: 0.3176470696926117, 82: 0.32156863808631897, 83: 0.32549020648002625, 84: 0.3294117748737335, 85: 0.3333333432674408, 86: 0.33725491166114807, 87: 0.34117648005485535, 88: 0.3450980484485626, 89: 0.3490196168422699, 90: 0.3529411852359772, 91: 0.35686275362968445, 92: 0.3607843220233917, 93: 0.364705890417099, 94: 0.3686274588108063, 95: 0.37254902720451355, 96: 0.3764705955982208, 97: 0.3803921639919281, 98: 0.3843137323856354, 99: 0.38823530077934265, 100: 0.3921568691730499, 101: 0.3960784375667572, 102: 0.4000000059604645, 103: 0.40392157435417175, 104: 0.40784314274787903, 105: 0.4117647111415863, 106: 0.4156862795352936, 107: 0.41960784792900085, 108: 0.42352941632270813, 109: 0.4274509847164154, 110: 0.4313725531101227, 111: 0.43529412150382996, 112: 0.43921568989753723, 113: 0.4431372582912445, 114: 0.4470588266849518, 115: 0.45098039507865906, 116: 0.45490196347236633, 117: 0.4588235318660736, 118: 0.4627451002597809, 119: 0.46666666865348816, 120: 0.47058823704719543, 121: 0.4745098054409027, 122: 0.47843137383461, 123: 0.48235294222831726, 124: 0.48627451062202454, 125: 0.4901960790157318, 126: 0.4941176474094391, 127: 0.49803921580314636, 128: 0.501960813999176, 129: 0.5058823823928833, 130: 0.5098039507865906, 131: 0.5137255191802979, 132: 0.5176470875740051, 133: 0.5215686559677124, 134: 0.5254902243614197, 135: 0.529411792755127, 136: 0.5333333611488342, 137: 0.5372549295425415, 138: 0.5411764979362488, 139: 0.545098066329956, 140: 0.5490196347236633, 141: 0.5529412031173706, 142: 0.5568627715110779, 143: 0.5607843399047852, 144: 0.5647059082984924, 145: 0.5686274766921997, 146: 0.572549045085907, 147: 0.5764706134796143, 148: 0.5803921818733215, 149: 0.5843137502670288, 150: 0.5882353186607361, 151: 0.5921568870544434, 152: 0.5960784554481506, 153: 0.6000000238418579, 154: 0.6039215922355652, 155: 0.6078431606292725, 156: 0.6117647290229797, 157: 0.615686297416687, 158: 0.6196078658103943, 159: 0.6235294342041016, 160: 0.6274510025978088, 161: 0.6313725709915161, 162: 0.6352941393852234, 163: 0.6392157077789307, 164: 0.6431372761726379, 165: 0.6470588445663452, 166: 0.6509804129600525, 167: 0.6549019813537598, 168: 0.658823549747467, 169: 0.6627451181411743, 170: 0.6666666865348816, 171: 0.6705882549285889, 172: 0.6745098233222961, 173: 0.6784313917160034, 174: 0.6823529601097107, 175: 0.686274528503418, 176: 0.6901960968971252, 177: 0.6941176652908325, 178: 0.6980392336845398, 179: 0.7019608020782471, 180: 0.7058823704719543, 181: 0.7098039388656616, 182: 0.7137255072593689, 183: 0.7176470756530762, 184: 0.7215686440467834, 185: 0.7254902124404907, 186: 0.729411780834198, 187: 0.7333333492279053, 188: 0.7372549176216125, 189: 0.7411764860153198, 190: 0.7450980544090271, 191: 0.7490196228027344, 192: 0.7529411911964417, 193: 0.7568627595901489, 194: 0.7607843279838562, 195: 0.7647058963775635, 196: 0.7686274647712708, 197: 0.772549033164978, 198: 0.7764706015586853, 199: 0.7803921699523926, 200: 0.7843137383460999, 201: 0.7882353067398071, 202: 0.7921568751335144, 203: 0.7960784435272217, 204: 0.800000011920929, 205: 0.8039215803146362, 206: 0.8078431487083435, 207: 0.8117647171020508, 208: 0.8156862854957581, 209: 0.8196078538894653, 210: 0.8235294222831726, 211: 0.8274509906768799, 212: 0.8313725590705872, 213: 0.8352941274642944, 214: 0.8392156958580017, 215: 0.843137264251709, 216: 0.8470588326454163, 217: 0.8509804010391235, 218: 0.8549019694328308, 219: 0.8588235378265381, 220: 0.8627451062202454, 221: 0.8666666746139526, 222: 0.8705882430076599, 223: 0.8745098114013672, 224: 0.8784313797950745, 225: 0.8823529481887817, 226: 0.886274516582489, 227: 0.8901960849761963, 228: 0.8941176533699036, 229: 0.8980392217636108, 230: 0.9019607901573181, 231: 0.9058823585510254, 232: 0.9098039269447327, 233: 0.9137254953384399, 234: 0.9176470637321472, 235: 0.9215686321258545, 236: 0.9254902005195618, 237: 0.929411768913269, 238: 0.9333333373069763, 239: 0.9372549057006836, 240: 0.9411764740943909, 241: 0.9450980424880981, 242: 0.9490196108818054, 243: 0.9529411792755127, 244: 0.95686274766922, 245: 0.9607843160629272, 246: 0.9647058844566345, 247: 0.9686274528503418, 248: 0.9725490212440491, 249: 0.9764705896377563, 250: 0.9803921580314636, 251: 0.9843137264251709, 252: 0.9882352948188782, 253: 0.9921568632125854, 254: 0.9960784316062927, 255: 1.0, 256: 1000.0}\n"
          ]
        }
      ],
      "source": [
        "print(itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VzUX2j5xTNqb"
      },
      "outputs": [],
      "source": [
        "# train and test splits\n",
        "data = torch.tensor(encode(train_data), dtype=torch.long)\n",
        "\n",
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I9jqiA4NTxT0"
      },
      "outputs": [],
      "source": [
        "# data loading\n",
        "def get_batch(split):\n",
        "  # generate a small batch of inputs x and targets y\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7yWXP-ZsULOw"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "R2jG1FH74fYc"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "  \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x) # (B, T, C)\n",
        "    q = self.query(x) # (B, T, C)\n",
        "    # compute attention scores (\"affinities\")\n",
        "    wei = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, C) @ (B, C, T) --> (B, T, T)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    wei = self.dropout(wei)\n",
        "    # perform the weighted aggregation of the values\n",
        "    v = self.value(x)\n",
        "    out = wei @ v # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7DZA6eK1zdMj"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embd, n_embd)\n",
        "    self.dropout = nn.Dropout(dropout) \n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ErBsUQCx1x-T"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embd, 4 * n_embd),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embd, n_embd),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wgGj-elk3SVn"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size)\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KBOvSGgfVOf4"
      },
      "outputs": [],
      "source": [
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # each token directly reads off the logits for the next token from a lookup table\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # n_embd: number of embedding dimensions\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "    self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "    self.ln_f = nn.LayerNorm(n_embd) # final layer norm    \n",
        "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "\n",
        "    B, T = idx.shape\n",
        "\n",
        "    # idx and targets are both (B, T) tensor of integers\n",
        "    tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
        "    x = tok_emb + pos_emb # (B, T, C)\n",
        "    x = self.blocks(x) # (B, T, C)\n",
        "    logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      # crop idx to the last block_size tokens\n",
        "      idx_cond = idx[:, -block_size:]\n",
        "      # get the predictions\n",
        "      logits, loss = self(idx_cond)\n",
        "      # focus only on the last time step\n",
        "      logits = logits[:, -1, :] # becomes (B, C)\n",
        "      # apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      # sample from the distribution\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      # append sampled index to the running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FhnpAOSFVlld"
      },
      "outputs": [],
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hSsCemUoVteA"
      },
      "outputs": [],
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTWbF_B_WGRA",
        "outputId": "04551167-5088-45bf-a9d0-84e2f86e1e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/Amirhk-dev/MNIST-Lab/main/experiments/notebooks/transformers/GPT-Dev-trained-on-MNIST.pt...\n",
            "Found pretrained model, loading...\n"
          ]
        }
      ],
      "source": [
        "base_url = \"https://raw.githubusercontent.com/Amirhk-dev/MNIST-Lab/main/experiments/notebooks/transformers/\"\n",
        "pretrained_file = [\"GPT-Dev-trained-on-MNIST.pt\"]\n",
        "file_name = pretrained_file[0]\n",
        "\n",
        "file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "file_url = base_url + file_name\n",
        "print(f\"Downloading {file_url}...\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(file_url, file_path)\n",
        "except HTTPError as e:\n",
        "  print(\"Something went wrong.\")\n",
        "\n",
        "if os.path.isfile(file_path):\n",
        "  print(\"Found pretrained model, loading...\")\n",
        "  m = torch.load(file_path, map_location=torch.device('cpu'))\n",
        "  m.eval()\n",
        "else:\n",
        "  print(\"Not Found the pretrained model!, The model must be trained on GPU!, start training...\")\n",
        "  \n",
        "  for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0:\n",
        "      losses = estimate_loss()\n",
        "      print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CotCpx9pF7ji",
        "outputId": "45c85c2c-71de-4eaf-c42e-d6ab29a050db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters of the model:\n",
            "\n",
            "10.936577 M parameters\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of parameters of the model:\\n\")\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKS75SEdRcNG"
      },
      "source": [
        "##Let's ask the model to generate MNIST-like image\n",
        "\n",
        "Here goes one of the well generated image by the trained model (it takes few minutes on CPU to generate).\n",
        "\n",
        "Unfortunately, the model does not always produce good images! The reason could be the number of images that are used to train the transformer (only 9K images), and further we have not yet considered the relation between the pixels on 2D image domain, i.e. the image pixels on 2D array are vectorised and considered as characters on text. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gyBlsWpcVz1Q",
        "outputId": "5fdff1d2-015e-4f1d-e164-77e07ff1dece"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "result = decode(m.generate(context, max_new_tokens=783)[0].tolist())\n",
        "img = np.reshape(result, (28, 28))\n",
        "img[np.where(img==1000)] = 0.0 # positions considered as the end of 28*28 pixels\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv15ExAVaEQVG0jfuq9yhk",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}